import os
import base64
from pydantic import BaseModel, Field
from langchain.chains import TransformChain
from langchain_core.messages import HumanMessage
from langchain_openai.chat_models import ChatOpenAI
from langchain import globals
from langchain_core.runnables import chain
from langchain_core.output_parsers import JsonOutputParser

# Configurando chave de API
os.environ["OPENAI_API_KEY"] = ''

# Função para carregar e codificar a imagem
def load_image(inputs: dict) -> dict:
    image_path = inputs["image_path"]
    def encode_image(image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    image_base64 = encode_image(image_path)
    return {"image": image_base64}

load_image_chain = TransformChain(
    input_variables=["image_path"],
    output_variables=["image"],
    transform=load_image
)

# Função para processar a imagem (substitua com uma API de visão computacional real)
def analyze_image(image_path: str) -> dict:
    # Simulação: Substitua este trecho com um analisador de visão computacional
    # (ex.: Google Vision API, Azure, ou OpenCV)
    # Exemplo fictício:
    return {
        "image_description": "A thermos bottle on a desk.",
        "people_count": 0,
        "main_objects": ["thermos", "desk"]
    }

# Modelo para representar informações da imagem
class ImageInformation(BaseModel):
    image_description: str = Field(description="A short description of the image")
    people_count: int = Field(description="Number of humans on the picture")
    main_objects: list[str] = Field(description="List of the main objects on the picture")

# Configurando debug
globals.set_debug(True)

# Modelo GPT-4 para interpretar informações baseadas na análise de imagem
@chain
def image_model(inputs: dict) -> str | list[str] | dict:
    model = ChatOpenAI(temperature=0.5, model="gpt-4", max_tokens=1024)

    # Criar o prompt com informações analisadas
    vision_data = analyze_image(inputs["image_path"])
    prompt = (
        f"Given the following analysis of an image, provide additional insights:\n"
        f"Image Description: {vision_data['image_description']}\n"
        f"People Count: {vision_data['people_count']}\n"
        f"Main Objects: {', '.join(vision_data['main_objects'])}\n\n"
        f"Please format the output as valid JSON matching the provided schema."
    )

    # Gerar saída textual
    msg = model.invoke([HumanMessage(content=prompt)])
    return msg.content

parser = JsonOutputParser(pydantic_object=ImageInformation)

# Função principal
def get_image_informations(image_path: str) -> dict:
    vision_chain = load_image_chain | image_model | parser
    return vision_chain.invoke({'image_path': image_path})

# Executando
result = get_image_informations(r"caminho da imagem")
print(result)
